---
title: "Processing Transpecial Data"
author: "Me"
date: "2/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(RPostgreSQL)
library(getPass)
library(lubridate)
library(data.table)
```

Establish connection
```{r}

pgdrv <- dbDriver(drvName = "PostgreSQL")
postgrescon <-DBI::dbConnect(pgdrv,
                    dbname="WTI",
                    host="localhost", port=5432,
                    user = 'postgres',
                    password = getPass("Enter Password:"))
```


```{r}
points_in_geofences <- dbGetQuery(postgrescon, "SELECT
	t.datestamp,
	t.plateno,
	g.name AS geofence_name
FROM 
	transpecial_gps_data AS t
JOIN
	nestle_geofence AS g
ON 
      ST_INTERSECTS(g.geom, t.geom);")
```



```{r}
points_in_geofences = points_in_geofences %>%
      mutate(datestamp = ymd_hms(datestamp))
      
points_in_geofences = points_in_geofences %>%
      arrange(datestamp)
```



- group by plateno, geofence, track_period
- compute for minimum timestamp, max timestamp, and number of points per group
- compute for duration
- filter only those with duration > 300 and num points > 5
```{r}
vehicle_location_group = points_in_geofences %>%
      mutate(track_period = floor_date(datestamp, '30 minutes')) %>%
      group_by(plateno, geofence_name, track_period) %>%
      mutate(time_start = min(datestamp),
             time_end = max(datestamp),
             num_points = n()) %>%
      mutate(duration = as.duration(time_end - time_start)) 



vehicle_location_group_reduced = vehicle_location_group%>%
      filter(duration  > 300 & num_points > 5) %>%
      arrange(plateno, geofence_name, track_period)


vehicle_location_group_reduced = vehicle_location_group_reduced %>%
      select(plateno, geofence_name, track_period, time_start, time_end, duration, num_points)  %>%
      distinct()
```




Create new variable morethan 5 mins for those that were sure to be inside the geofence for at least 5 mins
```{r}
morethan5mins = vehicle_location_group_reduced %>%
      arrange(plateno, track_period)

#Rename column
morethan5mins = morethan5mins %>%
      rename(duration_period_at_geofence = duration)

#remove initial checking
morethan5mins = morethan5mins %>%
      group_by(plateno, geofence_name) %>%
      arrange(plateno, geofence_name)
```




compute fo time difference from previous location and next location
```{r}
morethan5mins = morethan5mins %>%
      mutate(time_end_previous_location = lag(time_end),
             time_start_next_location = lead(time_start)) %>%
      mutate(time_difference_to_next_location = as.duration(time_start_next_location - time_end),
             time_difference_from_prev_location =as.duration(time_start - time_end_previous_location)) 

```

Select columns
```{r}
morethan5mins = morethan5mins %>%
      select(plateno,
             geofence_name,
             time_start, 
             time_end,
             time_end_previous_location,
             time_start_next_location,
             duration_period_at_geofence,
             time_difference_to_next_location,
             time_difference_from_prev_location,
             everything())
```

No need to run
```{r}
#create csv for checking
morethan5mins %>%
      ungroup() %>%
      mutate(track_period = as.character(track_period),
             time_start = as.character(time_start), 
             time_end = as.character(time_end), 
             time_end_previous_location = as.character(time_end_previous_location),
             time_start_next_location = as.character(time_start_next_location),
             ) %>%
      write_csv('checking.csv')
```


Process overlapping 30 mins
```{r}
#create boolean to check if is within 3 mins from previous track period
morethan5mins = morethan5mins %>%
        mutate(continue_next_location = time_difference_to_next_location < 300,
               contine_prev_location = time_difference_from_prev_location < 300)  %>%
      mutate(continue_both_location = contine_prev_location & continue_next_location)

#filter out data to record only entry and exit 
morethan5mins = morethan5mins %>%
      filter(continue_both_location == F | is.na(continue_both_location))


```



```{r}
#compute for actual end time
morethan5mins = morethan5mins %>%
      group_by(plateno, geofence_name) %>%
      mutate(actual_time_end = if_else(
            (is.na(time_end_previous_location) | lead(time_difference_from_prev_location)  < 300) 
            & !(time_difference_to_next_location > 300), 
            lead(time_end),
            time_end
      )) 

```

Final processing
```{r}

#filter no actual time end because they are the last for that location
#select relevant columns
#compute for duration at geofence
morethan5mins = morethan5mins%>%
      filter(!is.na(actual_time_end)) %>%
      select(plateno, geofence_name, time_start, actual_time_end) %>%
       mutate(duration_at_geofence = as.duration(actual_time_end - time_start))

#create ranking based on duration
fixed_data = morethan5mins %>%
      group_by(plateno, geofence_name, actual_time_end) %>%
      mutate(rank = rank(desc(duration_at_geofence)))


#remove the last entry
fixed_data = fixed_data %>%
      filter(rank != 2) 

#ungroup and select cols
fixed_data = fixed_data %>%
      ungroup() %>%
      select(plateno, 
             geofence_name,
             first_timestamp = time_start, 
             last_timestamp = actual_time_end, 
             time_duration_at_geofence = duration_at_geofence)
```


```{r}
fixed_data%>%
      mutate(first_timestamp = as.character(first_timestamp),
             last_timestamp = as.character(last_timestamp)) %>%
      write_csv('fixed_data.csv')
```



Arranged fixed data
```{r} 
fixed_data_arranged = fixed_data %>%
            arrange(plateno, first_timestamp) %>%
      group_by(plateno) %>%
      mutate(time_next = lead(first_timestamp)) %>%
      mutate(time_next = as.duration(time_next - last_timestamp))

fixed_data_arranged %>%
      mutate(first_timestamp = as.character(first_timestamp),
             last_timestamp = as.character(last_timestamp)) %>%
      write_csv('fixed_data_arranged.csv')
```


## Checking of errors
```{r}
fixed_data_arranged %>%
      mutate(check_duplicate = time_duration_at_geofence + time_next) %>%
      filter(time_next < 0) %>%
      filter(check_duplicate < -1 | check_duplicate > 1 )
```



```{r}
fixed_data_arranged %>%
      mutate(check_duplicate = time_duration_at_geofence + time_next) %>%
      filter(time_next < -300) %>%
      filter(check_duplicate < -300 | check_duplicate > 300 )
```

```{r}
fixed_data_arranged %>%
      mutate(check_duplicate = time_duration_at_geofence + time_next) %>%
      filter(time_next < 0) %>%
      filter(check_duplicate < -1 | check_duplicate > 1 ) %>%
      distinct(geofence_name) %>%
      filter(str_detect(geofence_name, 'Destination|Source'))
```



## Data validation

GPS CICO output
```{r}
fixed_data_arranged %>%
      select(first_timestamp, everything()) %>%
      filter(plateno == 'ADC4769', geofence_name== 'PH Cofipack - Source')
```


```{r}
points_group = points_in_geofences %>%
      mutate(track_period = floor_date(datestamp, '30 minutes')) %>%
      group_by(plateno, geofence_name, track_period) %>%
      mutate(time_start = min(datestamp),
             time_end = max(datestamp),
             num_points = n()) %>%
      mutate(duration = as.duration(time_end - time_start))
```

GPS RAW DATA GROUP
```{r}
points_group %>%
       filter(plateno == 'ADC4769', geofence_name== 'PH Cofipack - Source') %>%
   arrange(datestamp)
```




## Output to CSV

```{r}
fixed_data_arranged %>%
      arrange(first_timestamp) %>%
      mutate(first_timestamp = as.character(first_timestamp),
             last_timestamp = as.character(last_timestamp)) %>%
      write_csv('GPS_CICO.csv')
```


```{r}
cico = read_csv('GPS_CICO.csv')
```














