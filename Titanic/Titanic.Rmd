---
title: "Titanic"
author: "Me"
date: "8/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
theme_set(theme_light())
```

# Read data
```{r}
train_raw = read_csv('train.csv')
test_raw = read_csv('test.csv')
gender_submission = read_csv('gender_submission.csv')
```


# Data manipulation/ Wrangling
This section includes all the data manipulation from the EDA

- Mutated Pclass and Survived to factor
- detected if the name has parenthesis and added a variable has_parenthesis
- cut fares into bins
- created has_cabin if the passenger has an entry in cabin data. Divided into quantiles
- replaced missing embarked with 'C'
- Checked if the ticket has PC. it seems that this ticket is high class
- created another variable has_other_tickets which is 1 if you have letters in your ticket
- created new_variable has_numbered_ticket if the ticket has only numbers

```{r}
train = train_raw %>%
  mutate(Pclass = factor(Pclass),
         Survived = factor(Survived)) %>%
    mutate(has_parenthesis = factor(ifelse(str_detect(.$Name, '\\(.*\\)'), 1, 0))) %>%
    mutate(CutFare = cut(Fare, breaks = c(-1, 0, 7.91, 14.45, 31, 513), labels = c('Free','1stQ','2ndQ','3rdQ','4thQ'))) %>%
    mutate(has_cabin = factor(ifelse(!is.na(Cabin), 1, 0))) %>%
    replace_na(list(Embarked = 'C')) %>%
  mutate(Embarked = factor(Embarked),
         Sex = factor(Sex)) %>%
  mutate(has_PC_ticket = factor(if_else(str_detect(.$Ticket,'PC'), 1, 0))) %>%
  mutate(has_others_ticket = factor(ifelse(str_detect(.$Ticket,'[A-z]') & !str_detect(.$Ticket,'PC'), 1, 0))) %>%
   mutate(has_numbered_ticket = factor(ifelse(str_detect(.$Ticket, '[A-z]', negate = T), 1, 0)))

train %>%
  filter(is.na(Age))

#median age of masters

median_master_age = train %>% 
  filter(str_detect(.$Name, 'Master')) %>%
  summarise(median_master_age = median(Age, na.rm = T)) %>%
  .$median_master_age

ids = train %>%
  filter(str_detect(.$Name, 'Master'), is.na(Age)) %>%
  .$PassengerId

train[train$PassengerId %in% ids, 'Age'] = median_master_age

#set the missing age to median age
train = train %>%
  mutate(Age = coalesce(Age, median(train$Age, na.rm = T)))
```


#EDA

Check each variable

Pclass
```{r}
#complete data on pclass
train %>%
  filter(is.na(Pclass))

train %>%
  count(Pclass, Survived) %>%
  ggplot(aes(Survived, n, fill = Pclass))+
  geom_col(position = 'dodge')
```
Pclass has something to do with the survival

Name
If you have parenthesis on name you will likely survive
```{r}
#maybe having a master on a name is just random

train %>%
  filter(has_parenthesis == 1) %>%
  count(Survived) %>%
  ggplot(aes(Survived, n))+
  geom_col()+
  labs(title =  'Has parenthesis on names')
```

Sex
```{r}
train %>%
  count(Survived, Sex) %>%
  ggplot(aes(Survived, n, fill = Sex))+
  geom_col()+
  facet_wrap(~Sex)
```
It seems that sex is also a predictor whether you will survive or not. Girls are more likely to survive

Sibsp - number of siblings


```{r}
train %>%
  count(Survived, SibSp = factor(SibSp)) %>%
  arrange(desc(SibSp)) %>%
  ggplot(aes(Survived, n, fill = SibSp))+
  geom_col(position = 'dodge')
```
If you have siblings above 4, it will likely that you iwll not survive. Let us leave SibSp alone

Age
```{r}
train %>%
  ggplot(aes(Age, fill = Survived))+
  geom_histogram(position = 'identity', alpha = .5)
```

What well do is that we will just add the median age to all those missing and try to add 3.5 if you have master in your age


```{r}
median(train$Age, na.rm = T)
ids = train %>%
  filter(str_detect(.$Name, 'Master'), is.na(Age)) %>%
  .$PassengerId

train %>%
  filter(str_detect(.$Name, 'Master'))
```

Check age and Fare.

```{r}
train %>%
  ggplot(aes(Age, Fare))+
  geom_point()
```
There are three high fares. Let's check this. I think we can see it later if the TIcket has PC then you might be placed somewhere better. My idea for now is to bin the fares

```{r}
train %>%
  filter(Fare == max(Fare))
```

```{r}
train %>%
  count(Survived, CutFare) %>%
  ggplot(aes(Survived, n, fill = CutFare))+
  geom_col()+
  facet_wrap(~CutFare)

```

You are more likely to survive if you're fare is above 3rd or 4th quantile


Let's try to fix again the age
```{r}
train %>%
  group_by(CutFare) %>%
  summarise(median_age = median(Age, na.rm = T))
```

I think well just set the age to median which is 28


Parch
```{r}
train %>%
  count(Parch, Survived) %>%
  arrange(desc(Parch))
```

This is like the same as siblings. 

I think Fare is more dependent on Cabin rather than the ticket number
```{r}
train %>%
  count(has_cabin, Survived) %>%
  arrange(desc(Survived))
```

Well create a new variable has cabin

Try to check Fare
```{r}
train %>%
  filter(str_detect(.$Ticket, '[A-z]')) %>%
  count(Survived)
```

I think that the Fare will just determine the socioeconomic class of the passenger rather than if the ticket contains a letter or what not

Embarked
```{r}
train %>%
  count(Survived, Embarked) %>%
  ggplot(aes(Survived, n, fill = Embarked))+
  geom_col()+
  facet_wrap(~Embarked)
```
You are less likely to survive if you are going to S?

There are two missing values. Check

```{r}
#Ticket is 113572
train %>%
  filter(is.na(Embarked))

train %>%
  filter(str_detect(.$Ticket, '113'))
```

I think the missing value are embarked in S

Check the fare
```{r}
train %>%
  mutate(Embarked = fct_reorder(Embarked, Fare))%>%
  ggplot(aes(Embarked, Fare))+
  geom_boxplot()
```
Those with missing Embarked have higher Fare. Let's just include them in C or S

Add effect to ticket

```{r}
train %>%
  mutate(has_PC_ticket = factor(if_else(str_detect(.$Ticket,'PC'), 1, 0))) %>%
  mutate(has_others_ticket = factor(ifelse(str_detect(.$Ticket,'[A-z]') & !str_detect(.$Ticket,'PC'), 1, 0))) %>%
   mutate(has_numbered_ticket = factor(ifelse(str_detect(.$Ticket, '[A-z]', negate = T), 1, 0)))
```


### Fix the test


```{r}
test_ids = test_raw %>%
  filter(str_detect(.$Name, 'Master'), is.na(Age)) %>%
  .$PassengerId

master_test_median_age = test_raw %>%
  filter(str_detect(.$Name, 'Master')) %>%
  summarise(age = median(Age, na.rm = T)) %>%
  .$age

summary(test_raw$Fare)
```

```{r}
test = test_raw %>%
   mutate(Pclass = factor(Pclass)) %>%
  mutate(has_parenthesis = factor(ifelse(str_detect(.$Name, '\\(.*\\)'), 1, 0))) %>%
  replace_na(list(Fare = median(test_raw$Fare, na.rm = T))) %>%
  mutate(CutFare = cut(Fare, breaks = c(-1, 0, 7.89, 14.45, 31.5, 513), labels = c('Free','1stQ','2ndQ','3rdQ','4thQ'))) %>%
    mutate(has_cabin = factor(ifelse(!is.na(Cabin), 1, 0)))  %>%
    replace_na(list(Embarked = 'C')) %>%
  mutate(Embarked = factor(Embarked),
         Sex = factor(Sex)) %>%
  mutate(has_PC_ticket = factor(if_else(str_detect(.$Ticket,'PC'), 1, 0))) %>%
  mutate(has_others_ticket = factor(ifelse(str_detect(.$Ticket,'[A-z]') & !str_detect(.$Ticket,'PC'), 1, 0))) %>%
   mutate(has_numbered_ticket = factor(ifelse(str_detect(.$Ticket, '[A-z]', negate = T), 1, 0)))

test %>%
  filter(is.na(Age))

test[test$PassengerId %in% test_ids, 'Age'] = master_test_median_age

test = test %>%
  mutate(Age = coalesce(Age, median(test$Age, na.rm = T)))
```


```{r}
str(test)
```
```{r}
str(train)
```

## Modeling
Remove the ff
Name
Ticket
Cabin
Passenger ID

```{r}
model_data = train %>%
  select(-PassengerId, -Ticket, -Cabin, -Name)
```



#Split the train data to test different models

```{r}
model_data_train = model_data %>%
  sample_n(600)

model_data_test = model_data %>%
  setdiff(model_data_train)
```


# Support vector machien

```{r}
library(e1071)
svm.linear = svm(Survived ~., data = model_data_train, kernel = 'linear', cost = 10)
plot(svm.linear, model_data_train)

pred = predict(svm.linear, model_data_test)
length(pred)

table(pred, model_data_test$Survived)
```
Using linear kernel with cost 10, we have an accuracy of 77%

Try different cost
```{r}
cost = 10^seq(-3,3, by = .5)
res = tune(svm, Survived ~., data = model_data_train, kernel = 'linear', ranges = list(cost = cost))
best_mod = res$best.model

pred = predict(best_mod, model_data_test)
length(pred)

table(pred, model_data_test$Survived)
```
76%

```{r}
tune_out = tune(svm, Survived ~. -Fare , 
                data = model_data_train,
                kernel = 'linear',
                ranges = list(cost = c(.001, .01, .1, 1,5,10,100)))

best_mod = tune_out$best.model
pred = predict(best_mod, model_data_test)

table(pred, model_data_test$Survived)
```
Try radial

```{r}
gammas = 10^(seq(-3,-1,by=1))
rad_res = tune(svm, Survived ~., data = model_data_train, ranges = list(cost = c(.1,1,5,10,100), gamma = gammas), kernel = 'radial')

best_mod = rad_res$best.model
pred = predict(best_mod, model_data_test)

table(pred, model_data_test$Survived)
```
Halos same lang. Better if linear

# Random FOrest

```{r}
library(randomForest)

set.seed(1)

rf_model = randomForest(
  Survived ~ ., 
  data = model_data_train,
  mtry = 5,
  importance = T
)

pred = predict(rf_model, model_data_test)
table(pred, model_data_test$Survived)
```
Random forest has higher accuracy



Try different values of mtry

```{r}
mtry = 1:13
errors = double(length(mtry))
set.seed(927)

for (i in seq_along(mtry)){
  m = mtry[i]
  rf_mod = randomForest(Survived ~., data = model_data_train, mtry = m)
  pred = predict(rf_mod, newdata = model_data_test)
  table = table(pred, model_data_test$Survived)
  df_table = table %>% as.data.frame()
  sum = df_table %>%
  filter(pred == Var2) %>%
  summarise(sum = sum(Freq)) %>%
  .$sum
  errors[i] = sum/253
  
}

plot(errors)
```
Highest accuracy at mtry = 5

```{r}
rf_mod = randomForest(Survived ~. , data = model_data_train, mtry = 5)
pred = predict(rf_mod, newdata = model_data_test)
table = table(pred, model_data_test$Survived)
sum = df_table %>%
  filter(pred == Var2) %>%
  summarise(sum = sum(Freq)) %>%
  .$sum


table
```
78% accuracy

#Logistic

```{r}
library(glmnet)
glm_fit = glm(Survived ~., data = model_data_train, family = binomial)
pred = predict(glm_fit, model_data_test, type = 'response')
pred = ifelse(pred >.5, 1, 0)
table(pred, model_data_test$Survived)
```
76%. I'll just go with random forest

# Create a model from the whole dataset

Ill create a random forest from the whole dataset and use it to predict the test data

```{r}
rf_model = randomForest(
  Survived ~ ., 
  data = model_data,
  mtry = 5,
  importance = T
)

plot(rf_model)
summary(rf_model)
varImpPlot(rf_model)
```

From here, Sex, age, Pclass, Fare, and has_parenthesis are the most important factor. Ticket is not that important

```{r}
pred = predict(rf_model, test)
table(pred)
```

```{r}
my_prediction = test %>%
  mutate(Survived = pred) %>%
  select(PassengerId, Survived)
```


#Write output file
```{r}
write_csv(my_prediction, 'my_submission.csv')
```







