---
title: "Cleaning CICO data"
author: "Me"
date: "2/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
```

```{r}
remove_duplicates = function(file_name){
      data = read_csv(file_name)
      
      #select only needed cols
      data = data %>%
            select(-time_duration_at_geofence, -time_next)
      
      # floor to 1 minute
      # data = data %>%
      #       mutate(first_timestamp = floor_date(first_timestamp, '1 minute'),
      #              last_timestamp = floor_date(last_timestamp, '1 minute'))
      
      data = data %>%
            arrange(plateno, first_timestamp, geofence_name)
      # Remove continuning
      data = data %>%
            mutate(continuing = if_else(geofence_name == lead(geofence_name) & geofence_name == lag(geofence_name), 1, 0)) %>%
            filter(continuing == 0)
      
      data = data %>%
            select(-continuing) %>%
            mutate(has_same_next = ifelse(geofence_name == lead(geofence_name), 1, 0))

      data = data %>%
            mutate(new_last_timestamp = if_else(has_same_next == 1, lead(last_timestamp), last_timestamp)) %>%
            mutate(to_remove = lag(has_same_next == 1)) %>%
            filter(to_remove != T) %>%
            select(-last_timestamp, -to_remove, -has_same_next) %>%
            rename(last_timestamp = new_last_timestamp)
      return(data)
}

fixed_data = remove_duplicates('input_data/pan_cico.csv')
fixed_data %>%
      mutate(first_timestamp = as.character(first_timestamp),
             last_timestamp = as.character(last_timestamp)) %>%
      write_csv('PAN_CICO_normalize_ver1.csv')
```

# Process

Load data
```{r}
data = read_csv('input_data/transpecial_cico.csv')
```
Process data
```{r}
#select only needed cols
data = data %>%
      select(-time_duration_at_geofence, -time_next)

# floor to 1 minute
# data = data %>%
#       mutate(first_timestamp = floor_date(first_timestamp, '1 minute'),
#              last_timestamp = floor_date(last_timestamp, '1 minute'))

data = data %>%
      arrange(plateno, first_timestamp, geofence_name)
# Remove continuning
data = data %>%
      mutate(continuing = if_else(geofence_name == lead(geofence_name) & geofence_name == lag(geofence_name), 1, 0)) %>%
      filter(continuing == 0)
```

```{r}
#check if continuing location then adjust time
data = data %>%
      select(-continuing) %>%
      mutate(has_same_next = ifelse(geofence_name == lead(geofence_name), 1, 0))

data = data %>%
      mutate(new_last_timestamp = if_else(has_same_next == 1, lead(last_timestamp), last_timestamp)) %>%
      mutate(to_remove = lag(has_same_next == 1)) %>%
      filter(to_remove != T) %>%
      select(-last_timestamp, -to_remove, -has_same_next) %>%
      rename(last_timestamp = new_last_timestamp)
```


Create a function to normalize

```{r}
make_fo_and_normalize = function(cico_file_name, pattern_file_name){
      
      #load data and pattern
      data = read_csv(cico_file_name)
      pattern = read_csv(pattern_file_name)
      
      #add pattern to data
      data = data %>%
      left_join(pattern)
      
      # transform to fo format
      data = data %>%
            select(-last_timestamp) %>%
            rename(entry_time = first_timestamp) %>%
            arrange(plateno, entry_time) %>%
            mutate(source = ifelse(pattern == 1, geofence_name, NA)) %>%
            mutate(source_entrytime = if_else(pattern == 1, as.character(entry_time), NA_character_)) %>%
            group_by(plateno) %>%
            fill(source) %>%
            fill(source_entrytime)
      
      # arrange cols
      data = data %>%
            select(plateno,
                   source_geofence = source,
                   dest_geofence = geofence_name,
                   source_entrytime,
                   dest_entrytime = entry_time,
                   everything())
      
      #remove source geofence and dest geofence
      data = data %>%
            filter(pattern != 1 & !is.na(source_geofence)) %>%
            select( -pattern)     
      
      #normalize data by removing continuining
      normalized = data %>%
            arrange(plateno, source_entrytime) %>%
            group_by(plateno, source_geofence) %>%
            mutate(continuing = if_else(dest_geofence == lag(dest_geofence), 1, 0)) %>%
            filter(continuing == 0 | is.na(continuing)) %>%
            select(-continuing)
      
      normalized = normalized %>%
            mutate(source_entrytime = as.character(source_entrytime),
                   dest_entrytime = as.character(dest_entrytime))
      
      return(normalized)
}

normalized_EHD = make_fo_and_normalize('CICO normalized/EHD_CICO_normalize_ver1.csv','data_pattern/ehd_pattern.csv')
normalized_PAN = make_fo_and_normalize('CICO normalized/PAN_CICO_normalize_ver1.csv','data_pattern/pan_pattern.csv')
normalized_TRANS = make_fo_and_normalize('CICO normalized/Trans_CICO_normalize_ver1.csv','data_pattern/transpecial_pattern.csv')

normalized_TRANS 
```
Write them to CSV
```{r}
normalized_EHD %>%
      write_csv('normalized_ehd_cico_fo_ver1.csv')

normalized_PAN %>%
      write_csv('normalized_pan_cico_fo_ver1.csv')

normalized_TRANS %>%
      write_csv('normalized_trans_cico_fo_ver1.csv')
```


## Normalize data to FO format
load data
```{r}
data = read_csv('CICO normalized/EHD_CICO_normalize_ver1.csv')
pattern = read_csv('data_pattern/ehd_pattern.csv')
```

# Combine pattern

```{r}
data = data %>%
      left_join(pattern)
      
data = data %>%
      select(-last_timestamp) %>%
      rename(entry_time = first_timestamp) %>%
      arrange(plateno, entry_time) %>%
      mutate(source = ifelse(pattern == 1, geofence_name, NA)) %>%
      mutate(source_entrytime = if_else(pattern == 1, as.character(entry_time), NA_character_)) %>%
      group_by(plateno) %>%
      fill(source) %>%
      fill(source_entrytime)

data = data %>%
      select(plateno,
             source_geofence = source,
             dest_geofence = geofence_name,
             source_entrytime,
             dest_entrytime = entry_time,
             everything())

data = data %>%
      filter(pattern != 1 & !is.na(source_geofence)) %>%
      select( -pattern)

data
```
Normalize FO data
```{r}
normalized = data %>%
      arrange(plateno, source_entrytime) %>%
      group_by(plateno, source_geofence) %>%
      mutate(continuing = if_else(dest_geofence == lag(dest_geofence), 1, 0)) %>%
      filter(continuing == 0 | is.na(continuing)) %>%
      select(-continuing)

normalized = normalized %>%
      mutate(source_entrytime = as.character(source_entrytime),
             dest_entrytime = as.character(dest_entrytime))
      
```




